---
sidebar_position: 2
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Set Up with Locally

## Prepare

Before you getting start the local run, you need to make sure you already have installed the following software which SeaTunnel required:

* [Java](https://www.java.com/en/download/) (Java 8 or 11, other versions greater than Java 8 can theoretically work as well) installed and `JAVA_HOME` set.
* Download the engine, you can choose and download one of them from below as your favour, you could see more information about [why we need engine in SeaTunnel](../faq.md#why-i-should-install-computing-engine-like-spark-or-flink)
  * Spark: Please [download Spark](https://spark.apache.org/downloads.html) first(**required version >= 2 and version < 3.x **). For more information you could
  see [Getting Started: standalone](https://spark.apache.org/docs/latest/spark-standalone.html#installing-spark-standalone-to-a-cluster)
  * Flink: Please [download Flink](https://flink.apache.org/downloads.html) first(**required version >= 1.12.0 and version < 1.14.x **). For more information you could see [Getting Started: standalone](https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/deployment/resource-providers/standalone/overview/)

## Installation

Enter the [seatunnel download page](https://seatunnel.apache.org/download) and download the latest version of distribute
package `seatunnel-<version>-bin.tar.gz`

Or you can download it by terminal

```shell
export version="2.1.0"
wget "https://archive.apache.org/dist/incubator/seatunnel/${version}/apache-seatunnel-incubating-${version}-bin.tar.gz"
tar -xzvf "apache-seatunnel-incubating-${version}-bin.tar.gz"
```
<!-- TODO: We should add example module as quick start which is no need for install Spark or Flink -->

## Install connectors plugin
Since 2.2.0-beta, the binary package does not provide connector dependencies by default, so when using it for the first time, we need to execute the following command to install the connector: (Of course, you can also manually download the connector from [Apache Maven Repository](https://repo. maven.apache.org/maven2/org/apache/seatunnel/ to download, then manually move to the connectors directory).
```bash
sh bin/install_plugin.sh
```
If you need to specify the version of the connector, take 2.2.0-beta as an example, we need to execute
```bash
sh bin/install_plugin.sh 2.2.0-beta
```
Usually we don't need all the connector plugins, so you can specify the plugins you need by configuring `config/plugin_config`, for example, you only need the `flink-assert` plugin, then you can modify plugin.properties as
```plugin_config
--flink-connectors--
seatunnel-connector-flink-assert
--end--
```

## Run SeaTunnel Application

**Configure SeaTunnel**: Change the setting in `config/seatunnel-env.sh`, it is base on the path your engine install at [prepare step two](#prepare).
Change `SPARK_HOME` if you using Spark as your engine, or change `FLINK_HOME` if you're using Flink.

**Run Application with Build-in Configure**: We already provide an out-of-box configuration in the directory `config` which
you could find when you extract the tarball. You could start the application by the following commands

<Tabs
  groupId="engine-type"
  defaultValue="spark"
  values={[
    {label: 'Spark', value: 'spark'},
    {label: 'Flink', value: 'flink'},
  ]}>
<TabItem value="spark">

```shell
cd "apache-seatunnel-incubating-${version}"
./bin/start-seatunnel-spark.sh \
--master local[4] \
--deploy-mode client \
--config ./config/spark.streaming.conf.template
```

</TabItem>
<TabItem value="flink">

```shell
cd "apache-seatunnel-incubating-${version}"
./bin/start-seatunnel-flink.sh \
--config ./config/flink.streaming.conf.template
```

</TabItem>
</Tabs>

**See The Output**: When you run the command, you could see its output in your console or in Flink UI, You can think this
is a sign that the command ran successfully or not.

<Tabs
  groupId="engine-type"
  defaultValue="spark"
  values={[
    {label: 'Spark', value: 'spark'},
    {label: 'Flink', value: 'flink'},
  ]}>
<TabItem value="spark">
The SeaTunnel console will prints some logs as below:

```shell
Hello World, SeaTunnel
Hello World, SeaTunnel
Hello World, SeaTunnel
...
Hello World, SeaTunnel
```

</TabItem>
<TabItem value="flink">

The content printed in the TaskManager Stdout log of `flink WebUI`, is two columned record just like below(your
content maybe different cause we use fake source to create data random):

```shell
apache, 15
seatunnel, 30
incubator, 20
...
topLevel, 20
```

</TabItem>
</Tabs>

## Explore More Build-in Examples

Our local quick start is using one of the build-in example in directory `config`, and we provide more than one out-of-box
example you could and feel free to have a try and make your hands dirty. All you have to do is change the started command
option value in [running application](#run-seaTunnel-application) to the configuration you want to run, we use batch
template in `config` as examples:

<Tabs
    groupId="engine-type"
    defaultValue="spark"
    values={[
        {label: 'Spark', value: 'spark'},
        {label: 'Flink', value: 'flink'},
    ]}>
<TabItem value="spark">

```shell
cd "apache-seatunnel-incubating-${version}"
./bin/start-seatunnel-spark.sh \
--master local[4] \
--deploy-mode client \
--config ./config/spark.batch.conf.template
```

</TabItem>
<TabItem value="flink">

```shell
cd "apache-seatunnel-incubating-${version}"
./bin/start-seatunnel-flink.sh \
--config ./config/flink.batch.conf.template
```

</TabItem>
</Tabs>

## What's More

For now, you are already take a quick look about SeaTunnel, you could see [connector](/category/connector) to find all
source and sink SeaTunnel supported. Or see [deployment](../deployment.mdx) if you want to submit your application in other
kind of your engine cluster.
